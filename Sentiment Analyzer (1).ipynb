{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699a5daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install packages and import libraries\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download([\n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd67a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "# Extracting concordance\n",
    "\n",
    "# Create new word list with stop words\n",
    "text = nltk.Text(nltk.corpus.state_union.words())\n",
    "text.concordance(\"america\", lines=5)\n",
    "\n",
    "# Create finders for trigrams, bigrams, quadgrams\n",
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "trigramfinder = nltk.collocations.TrigramCollocationFinder.from_words(words)\n",
    "bigramfinder = nltk.collocations.BigramCollocationFinder.from_words(words)\n",
    "quadgramfinder = nltk.collocations.QuadgramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a673197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> True Firmly believe Farage was brilliant then\n",
      "Hashtag speaks for itself http//t.co/YTlpVBXJ6t\n",
      "> False @ItsMe_Ryry online please :(\n",
      "> False Tbh, bestfriend breakups are even worse than relationship breakups. :(\n",
      "> False RT @StephenNoon: Miliband has just sacrificed @ScottishLabour - he'd let the Tories stay in government rather than work with the #SNP #mili…\n",
      "> True \"Good morning, beautiful :)\" That's all it takes.\n",
      "> True Yes, Pearson had that reputation. Does Nikkei have that reputation? Hmmm...ask Michael Woodford. :D @W7VOA @FT\n",
      "> False Ok, back to work :( http//t.co/QFtLZ2Cl0w\n",
      "> True @undeux you look amazing April love the glasses :D\n",
      "> True It sure sounded like it to me. Amatain! https//t.co/LGtaTDp5Hr\n",
      "> True RT @NicolaSturgeon: If Miliband is going to let Tories in rather than work with SNP, we will definitely need lots of SNP MPs to protect Sco…\n"
     ]
    }
   ],
   "source": [
    "# Using VADER \n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test VADER with twitter_samples and movie_samples databases\n",
    "\n",
    "# Load twitter_samples into a list of strings, rendering URLs inactive\n",
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]\n",
    "\n",
    "# Use polarity_scores function to classify tweers\n",
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet:str) -> bool:\n",
    "    return sia.polarity_scores(tweet)['compound'] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)\n",
    "\n",
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids\n",
    "\n",
    "# Rewrite is_positive to work on an entire review\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "def is_positive(review_id: str) -> bool:\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca424c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revealing effects of feature selection (specifically positive/negative) on SA\n",
    "\n",
    "# Exclude stopwords \n",
    "unwanted = nltk.corpus.stopwords.words('english')\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "# Function to skip stopwords\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Create sets of positive and negative words\n",
    "# Determine which occur most frequently\n",
    "\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]\n",
    "\n",
    "# Create frequency distributions for feature\n",
    "# Find words present in both positvie and negative word sets\n",
    "\n",
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}\n",
    "\n",
    "# Find meaningful collocations\n",
    "\n",
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "# Find positive bigrams such as \"well done\"\n",
    "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])\n",
    "\n",
    "# Find negative bigrams such as \"no good\"\n",
    "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1a3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                wordcount += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "\n",
    "    features[\"mean_compound\"] = mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = mean(positive_scores)\n",
    "    features[\"wordcount\"] = wordcount\n",
    "\n",
    "    return features\n",
    "\n",
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])\n",
    "\n",
    "# extract_features will return a dictionary with three features: \n",
    "# average compound score, average positive score, amount of words in the text\n",
    "# that are also in the top 100 words for all positive reviews\n",
    "\n",
    "# Build a list of features for each text to be analyzed\n",
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281720b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               wordcount = 2                 pos : neg    =      9.8 : 1.0\n",
      "               wordcount = 4                 pos : neg    =      3.1 : 1.0\n",
      "               wordcount = 0                 neg : pos    =      1.6 : 1.0\n",
      "               wordcount = 1                 pos : neg    =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
    "classifier.show_most_informative_features(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
